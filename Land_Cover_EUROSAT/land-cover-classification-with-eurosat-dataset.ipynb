{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1257124,"sourceType":"datasetVersion","datasetId":723027}],"dockerImageVersionId":29869,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"display:fill;\n           background-color:#F2E5E5;\n           letter-spacing:0.5px;border-bottom: 2px solid black;\">\n<img src=\"https://raw.githubusercontent.com/IqmanS/Machine-Learning-Notebooks/refs/heads/main/Land_Cover_EUROSAT/thumb.jpg\">\n<H1 style=\"padding: 20px; color:black; font-weight:600; font-family: 'Garamond', 'Lucida Sans', sans-serif; text-align: center; font-size: 38px;\">Land-Cover Classification with EuroSAT Dataset </H1>\n</div>\n","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\nimport random\nfrom tqdm import tqdm\n\nimport numpy as np\nimport pandas as pd\nimport re\n\nimport PIL\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom os import listdir\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# import imutils\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Flatten, Activation, Dense, MaxPooling2D, Dropout#, RandomRotation, RandomFlip, RandomContrast\nfrom tensorflow.keras import Sequential\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.utils import shuffle\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport tensorflow as tf\n# from keras.models import Model\n# from keras.layers import Dense, Dropout, Flatten\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n# from keras.optimizers import Adam\n\n\nfrom keras.applications import VGG16, VGG19, MobileNetV2 \nfrom keras.applications import ResNet50, ResNet50V2, ResNet152V2, ResNet101V2\nfrom keras.applications import InceptionV3, Xception\n\nfrom sklearn.metrics import precision_recall_fscore_support, confusion_matrix, fbeta_score, accuracy_score, f1_score, precision_score, recall_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T14:27:05.246973Z","iopub.execute_input":"2024-11-20T14:27:05.247256Z","iopub.status.idle":"2024-11-20T14:27:05.259989Z","shell.execute_reply.started":"2024-11-20T14:27:05.247229Z","shell.execute_reply":"2024-11-20T14:27:05.259142Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Exploration","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"IMAGE_DIR = \"../input/2750\"\nLABELS = os.listdir(IMAGE_DIR)\nprint(LABELS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T09:46:38.063904Z","iopub.execute_input":"2024-11-20T09:46:38.064086Z","iopub.status.idle":"2024-11-20T09:46:38.074921Z","shell.execute_reply.started":"2024-11-20T09:46:38.064066Z","shell.execute_reply":"2024-11-20T09:46:38.074228Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, axs = plt.subplots(6, 6,figsize=(12,12),dpi=500)\nfor i in range(6):\n    for j in range(6):\n        label = np.random.choice(LABELS)\n        number = np.random.randint(1000,2000)\n        img_path = IMAGE_DIR+\"/\"+label+\"/\"+label+\"_\"+str(number)+\".jpg\"\n        img = PIL.Image.open(img_path, 'r')\n        axs[i, j].imshow(img)\n        axs[i, j].axis(\"off\")\n\nfor ax in axs.ravel():\n    ax.set_axis_off();\n    \nplt.subplots_adjust(wspace=0, hspace=0);\n# plt.tight_layout();\nfig.patch.set_facecolor('black')\nplt.savefig(\"image.png\");\nplt.show();","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T09:48:47.406965Z","iopub.execute_input":"2024-11-20T09:48:47.407255Z","iopub.status.idle":"2024-11-20T09:48:53.494050Z","shell.execute_reply.started":"2024-11-20T09:48:47.407223Z","shell.execute_reply":"2024-11-20T09:48:53.493139Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def augment_data(file_dir, save_to_dir, n_generated_samples = 2):\n    data_gen = ImageDataGenerator(rotation_range=10, \n                                  width_shift_range=0.1, \n                                  height_shift_range=0.1, \n                                  shear_range=0.1, \n                                  brightness_range=(0.5, 1.0),\n                                  horizontal_flip=True, \n                                  vertical_flip=True, \n                                  fill_mode='nearest'\n                                 )\n\n    for filename in listdir(file_dir):\n        image = cv2.imread(file_dir + '/' + filename)\n        # reshape the image\n        image = image.reshape((1,)+image.shape)\n        save_prefix = 'aug_' + filename[:-4]\n        i=0\n        for batch in data_gen.flow(x=image, batch_size=1, save_to_dir=save_to_dir,save_prefix=save_prefix, save_format='jpg'):\n                i += 1\n                if i > n_generated_samples:\n                    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T09:49:17.113668Z","iopub.execute_input":"2024-11-20T09:49:17.113916Z","iopub.status.idle":"2024-11-20T09:49:17.119816Z","shell.execute_reply.started":"2024-11-20T09:49:17.113894Z","shell.execute_reply":"2024-11-20T09:49:17.119125Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# plot class distributions of whole dataset\ncounts = {}\n\nfor l in LABELS:\n    counts[l] = len(os.listdir(os.path.join(IMAGE_DIR, l)))\n\n    \nplt.figure(figsize=(12, 6))\n\nplt.bar(range(len(counts)), list(counts.values()), align='center')\nplt.xticks(range(len(counts)), list(counts.keys()), fontsize=12, rotation=40)\nplt.xlabel('class label', fontsize=13)\nplt.ylabel('class size', fontsize=13)\nplt.title('EUROSAT Class Distribution', fontsize=15);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T09:49:17.500236Z","iopub.execute_input":"2024-11-20T09:49:17.500486Z","iopub.status.idle":"2024-11-20T09:49:17.912313Z","shell.execute_reply.started":"2024-11-20T09:49:17.500460Z","shell.execute_reply":"2024-11-20T09:49:17.911488Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# SET SEED\nnp.random.seed(6)\nseed = np.random.randint(123)\nprint(seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T09:49:20.162652Z","iopub.execute_input":"2024-11-20T09:49:20.162919Z","iopub.status.idle":"2024-11-20T09:49:20.167318Z","shell.execute_reply.started":"2024-11-20T09:49:20.162895Z","shell.execute_reply":"2024-11-20T09:49:20.166617Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TRAIN_DIR = '../working/training'\nTEST_DIR = '../working/testing'\nBATCH_SIZE = 128\nNUM_CLASSES = len(LABELS)\nINPUT_SHAPE = (64, 64, 3)\nCLASS_MODE = 'categorical'\nTEST_SIZE = 0.25\n\nfor path in (TRAIN_DIR, TEST_DIR):\n    if not os.path.exists(path):\n        os.mkdir(path)\n\nfor l in LABELS:\n    if not os.path.exists(os.path.join(TRAIN_DIR, l)):\n        os.mkdir(os.path.join(TRAIN_DIR, l))\n\n    if not os.path.exists(os.path.join(TEST_DIR, l)):\n        os.mkdir(os.path.join(TEST_DIR, l))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T09:49:20.401797Z","iopub.execute_input":"2024-11-20T09:49:20.402019Z","iopub.status.idle":"2024-11-20T09:49:20.408893Z","shell.execute_reply.started":"2024-11-20T09:49:20.401995Z","shell.execute_reply":"2024-11-20T09:49:20.408280Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# map each image path to their class label in 'data'\ndata = {}\n\nfor l in LABELS:\n    for img in os.listdir(IMAGE_DIR+'/'+l):\n        data.update({os.path.join(IMAGE_DIR, l, img): l})\n\nX = pd.Series(list(data.keys()))\ny = pd.get_dummies(pd.Series(data.values()))\n\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=TEST_SIZE, random_state=seed)\n\n# split the list of image paths\nfor train_idx, test_idx in split.split(X, y):\n    \n    train_paths = X[train_idx]\n    test_paths = X[test_idx]\n\n    # define a new path for each image depending on training or testing\n    new_train_paths = [re.sub('\\.\\.\\/input\\/2750', '../working/training', i) for i in train_paths]\n    new_test_paths = [re.sub('\\.\\.\\/input\\/2750', '../working/testing', i) for i in test_paths]\n\n    train_path_map = list((zip(train_paths, new_train_paths)))\n    test_path_map = list((zip(test_paths, new_test_paths)))\n    \n    # move the files\n    # print(\"moving training files..\")\n    for i in tqdm(train_path_map,desc = \"Moving Training Data\"):\n        if not os.path.exists(i[1]):\n            if not os.path.exists(re.sub('training', 'testing', i[1])):\n                shutil.copy(i[0], i[1])\n    \n    # print(\"moving testing files..\")\n    for i in tqdm(test_path_map,desc = \"Moving Testing Data\"):\n        if not os.path.exists(i[1]):\n            if not os.path.exists(re.sub('training', 'testing', i[1])):\n                shutil.copy(i[0], i[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T09:49:20.783748Z","iopub.execute_input":"2024-11-20T09:49:20.783955Z","iopub.status.idle":"2024-11-20T09:52:04.597495Z","shell.execute_reply.started":"2024-11-20T09:49:20.783934Z","shell.execute_reply":"2024-11-20T09:52:04.596716Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a ImageDataGenerator Instance which can be used for data augmentation\n\ntrain_gen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=60,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    brightness_range=(0.5, 1.0),\n    horizontal_flip=True, \n    vertical_flip=True, \n    fill_mode='nearest'\n)\n\ntrain_generator = train_gen.flow_from_directory(\n    directory=TRAIN_DIR,\n    target_size=(64, 64),\n    batch_size=BATCH_SIZE,\n    class_mode=CLASS_MODE,\n    color_mode='rgb',\n    shuffle=True,\n    seed=seed\n)\n\n# test generator for evaluation purposes with no augmentations, just rescaling\ntest_gen = ImageDataGenerator(\n    rescale=1./255,\n)\n\ntest_generator = test_gen.flow_from_directory(\n    directory=TEST_DIR,\n    target_size=(64, 64),\n    batch_size=BATCH_SIZE,\n    class_mode=CLASS_MODE,\n    color_mode='rgb',\n    shuffle=False,\n    seed=seed\n)\n\npred_generator = test_gen.flow_from_directory(  #no batches\n    directory=TEST_DIR,\n    target_size=(64, 64),\n    batch_size=1,\n    class_mode=None,\n    color_mode='rgb',\n    shuffle=False,\n    seed=seed\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T09:52:04.599081Z","iopub.execute_input":"2024-11-20T09:52:04.599332Z","iopub.status.idle":"2024-11-20T09:52:06.898192Z","shell.execute_reply.started":"2024-11-20T09:52:04.599308Z","shell.execute_reply":"2024-11-20T09:52:06.897524Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_generator.class_indices)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T09:52:06.899310Z","iopub.execute_input":"2024-11-20T09:52:06.899516Z","iopub.status.idle":"2024-11-20T09:52:06.903327Z","shell.execute_reply.started":"2024-11-20T09:52:06.899492Z","shell.execute_reply":"2024-11-20T09:52:06.902695Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.save('class_indices', train_generator.class_indices)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T09:52:06.904569Z","iopub.execute_input":"2024-11-20T09:52:06.904827Z","iopub.status.idle":"2024-11-20T09:52:06.914918Z","shell.execute_reply.started":"2024-11-20T09:52:06.904798Z","shell.execute_reply":"2024-11-20T09:52:06.914324Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Building Deep Learning Models\n\n1. Custom CNN\n2. MobileNetV2\n3. ResNet101V2\n","metadata":{}},{"cell_type":"code","source":"N_STEPS = train_generator.samples//BATCH_SIZE\nN_VAL_STEPS = test_generator.samples//BATCH_SIZE\nN_EPOCHS = 100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T09:52:37.452619Z","iopub.execute_input":"2024-11-20T09:52:37.452886Z","iopub.status.idle":"2024-11-20T09:52:37.456992Z","shell.execute_reply.started":"2024-11-20T09:52:37.452862Z","shell.execute_reply":"2024-11-20T09:52:37.456073Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_history(history):\n       \n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    \n    plt.figure(figsize=(20, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(acc)\n    plt.plot(val_acc)\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='upper left')\n    plt.title(\"Acc vs Val Acc\")\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(loss)\n    plt.plot(val_loss)\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='upper left')\n    plt.title(\"Loss vs Val Loss\")\n    \n    plt.show();","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T09:52:37.673000Z","iopub.execute_input":"2024-11-20T09:52:37.673251Z","iopub.status.idle":"2024-11-20T09:52:37.680039Z","shell.execute_reply.started":"2024-11-20T09:52:37.673223Z","shell.execute_reply":"2024-11-20T09:52:37.679200Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"early_stop = EarlyStopping(monitor='val_accuracy',\n                           patience=4,\n                           restore_best_weights=True,\n                           mode='max')\n\nreduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,\n                              patience=3, min_lr=0.00001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T15:04:18.386518Z","iopub.execute_input":"2024-11-20T15:04:18.386769Z","iopub.status.idle":"2024-11-20T15:04:18.407663Z","shell.execute_reply.started":"2024-11-20T15:04:18.386746Z","shell.execute_reply":"2024-11-20T15:04:18.406815Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1. Custom CNN Model","metadata":{}},{"cell_type":"code","source":"def build_model(input_shape):\n    model = Sequential()\n    model.add(Input(input_shape))\n    model.add(Conv2D(16,5,activation=\"relu\"))\n    model.add(MaxPooling2D(2,2))\n    model.add(Conv2D(32,5,activation=\"relu\"))\n    model.add(Conv2D(32,5,activation=\"relu\"))\n    model.add(MaxPooling2D(2,2))\n    model.add(Conv2D(64,7,activation=\"relu\"))\n    model.add(MaxPooling2D(2,2))\n    model.add(Flatten())\n    model.add(Dense(100))\n    model.add(Dropout(0.2))\n    model.add(Dense(len(LABELS),activation=\"softmax\"))\n    return model\n\ncustom_model = build_model(INPUT_SHAPE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T13:02:57.968188Z","iopub.execute_input":"2024-11-20T13:02:57.968482Z","iopub.status.idle":"2024-11-20T13:02:58.083799Z","shell.execute_reply.started":"2024-11-20T13:02:57.968452Z","shell.execute_reply":"2024-11-20T13:02:58.083124Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_generator.reset()\ntest_generator.reset()\n\ncustom_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\ncustom_model_history = custom_model.fit_generator(train_generator, steps_per_epoch=N_STEPS, epochs=50,\n                                                  callbacks=[early_stop, reduce_lr],\n                                                  validation_data=test_generator, validation_steps=N_VAL_STEPS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T13:02:58.085104Z","iopub.execute_input":"2024-11-20T13:02:58.085372Z","iopub.status.idle":"2024-11-20T13:31:53.309511Z","shell.execute_reply.started":"2024-11-20T13:02:58.085347Z","shell.execute_reply":"2024-11-20T13:31:53.308838Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_history(custom_model_history)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T13:31:53.311314Z","iopub.execute_input":"2024-11-20T13:31:53.311517Z","iopub.status.idle":"2024-11-20T13:31:53.557721Z","shell.execute_reply.started":"2024-11-20T13:31:53.311489Z","shell.execute_reply":"2024-11-20T13:31:53.556870Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Transfer Learning MobileNetV2 ","metadata":{}},{"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom keras.optimizers import Adam","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T13:32:06.267373Z","iopub.execute_input":"2024-11-20T13:32:06.267612Z","iopub.status.idle":"2024-11-20T13:32:06.271902Z","shell.execute_reply.started":"2024-11-20T13:32:06.267588Z","shell.execute_reply":"2024-11-20T13:32:06.271142Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_mobilenet(input_shape, fine_tune=None):\n    conv_base = MobileNetV2(include_top=False,\n                             weights='imagenet', \n                             input_shape=input_shape)\n    base_model = conv_base.output\n    base_model = Flatten()(base_model)\n    base_model = Dense(1000)(base_model)\n    base_model = Dropout(0.2)(base_model)\n    output_layer = Dense(len(LABELS),activation=\"softmax\")(base_model) #o/p layer\n    model = Model(inputs=conv_base.input, outputs=output_layer)\n    if type(fine_tune) == int:\n        for layer in conv_base.layers[fine_tune:]: layer.trainable = True\n    else:\n        for layer in conv_base.layers: layer.trainable = False\n    return model\n\nmobilenet = build_mobilenet(INPUT_SHAPE,20)\n\ntrain_generator.reset()\ntest_generator.reset()\n\nmobilenet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmobilenet_history = mobilenet.fit_generator(train_generator, steps_per_epoch=N_STEPS, epochs=50,\n                                            callbacks=[early_stop, reduce_lr],\n                                            validation_data=test_generator, validation_steps=N_VAL_STEPS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T13:32:06.647438Z","iopub.execute_input":"2024-11-20T13:32:06.647666Z","iopub.status.idle":"2024-11-20T14:00:01.089886Z","shell.execute_reply.started":"2024-11-20T13:32:06.647645Z","shell.execute_reply":"2024-11-20T14:00:01.088885Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_history(mobilenet_history)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T14:00:01.092397Z","iopub.execute_input":"2024-11-20T14:00:01.092619Z","iopub.status.idle":"2024-11-20T14:00:01.413543Z","shell.execute_reply.started":"2024-11-20T14:00:01.092596Z","shell.execute_reply":"2024-11-20T14:00:01.412281Z"},"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Transfer Learning ResNet101V2 ","metadata":{}},{"cell_type":"code","source":"def build_resnet101(input_shape ,fine_tune=None):\n    conv_base = ResNet101V2(include_top=False,\n                             weights='imagenet', \n                             input_shape=input_shape)\n    base_model = conv_base.output\n    base_model = Flatten()(base_model)\n    base_model = Dense(1000)(base_model)\n    base_model = Dropout(0.2)(base_model)\n    output_layer = Dense(len(LABELS),activation=\"softmax\")(base_model) #o/p layer\n    model = Model(inputs=conv_base.input, outputs=output_layer)\n\n    if type(fine_tune) == int:\n        for layer in conv_base.layers[fine_tune:]: layer.trainable = True\n    else:\n        for layer in conv_base.layers: layer.trainable = False\n    \n    return model\n\nresnet = build_resnet101(INPUT_SHAPE,20)\n\ntrain_generator.reset()\ntest_generator.reset()\n\nresnet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nresnet_history = resnet.fit_generator(train_generator, steps_per_epoch=N_STEPS, epochs=50,\n                                      callbacks=[early_stop, reduce_lr],\n                                      validation_data=test_generator, validation_steps=N_VAL_STEPS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T10:46:54.727584Z","iopub.execute_input":"2024-11-20T10:46:54.727865Z","iopub.status.idle":"2024-11-20T11:25:56.633268Z","shell.execute_reply.started":"2024-11-20T10:46:54.727840Z","shell.execute_reply":"2024-11-20T11:25:56.632367Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_history(resnet_history)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T11:25:56.635796Z","iopub.execute_input":"2024-11-20T11:25:56.636022Z","iopub.status.idle":"2024-11-20T11:25:56.984989Z","shell.execute_reply.started":"2024-11-20T11:25:56.635998Z","shell.execute_reply":"2024-11-20T11:25:56.983658Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"def display_results(y_true, y_preds, class_labels):\n    \n    results = pd.DataFrame(precision_recall_fscore_support(y_true, y_preds),\n                          columns=class_labels).T\n    results.rename(columns={0: 'Precision',\n                           1: 'Recall',\n                           2: 'F-Score',\n                           3: 'Support'}, inplace=True)\n    \n    conf_mat = pd.DataFrame(confusion_matrix(y_true, y_preds), \n                            columns=class_labels,\n                            index=class_labels)    \n    accuracy = accuracy_score(y_true, y_preds)\n    f1 = f1_score(y_true, y_preds,average='macro')\n    precision = precision_score(y_true, y_preds,average='macro')\n    recall = recall_score(y_true, y_preds,average='macro')\n    \n    print(f\"Accuracy: {accuracy}\")\n    print(f\"F1 Score: {f1}\")    \n    print(f\"Precision Score: {precision}\")\n    print(f\"Recall Score: {recall}\")  \n    return results, conf_mat\n\ndef plot_predictions(y_true, y_preds, test_generator, class_indices):\n\n    fig = plt.figure(figsize=(20, 12))\n    for i, idx in enumerate(np.random.choice(test_generator.samples, size=20, replace=False)):\n        ax = fig.add_subplot(4, 5, i + 1, xticks=[], yticks=[])\n        ax.imshow(np.squeeze(test_generator[idx]))\n        pred_idx = np.argmax(y_preds[idx])\n        true_idx = y_true[idx]\n                \n        plt.tight_layout()\n        ax.set_title(\"{}\\n({})\".format(class_indices[pred_idx], class_indices[true_idx]),\n                     color=(\"green\" if pred_idx == true_idx else \"red\"))    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T14:32:43.789789Z","iopub.execute_input":"2024-11-20T14:32:43.790053Z","iopub.status.idle":"2024-11-20T14:32:43.799451Z","shell.execute_reply.started":"2024-11-20T14:32:43.790028Z","shell.execute_reply":"2024-11-20T14:32:43.798736Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluating Custom CNN Model","metadata":{}},{"cell_type":"code","source":"class_indices = train_generator.class_indices\nclass_indices = dict((v,k) for k,v in class_indices.items())\npred_generator.reset()\n\npredictions = custom_model.predict_generator(pred_generator, steps=len(pred_generator.filenames))\npredicted_classes = np.argmax(np.rint(predictions), axis=1)\ntrue_classes = pred_generator.classes\n\nprf, conf_mat = display_results(true_classes, predicted_classes, class_indices.values())\nprf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T14:32:44.827449Z","iopub.execute_input":"2024-11-20T14:32:44.827690Z","iopub.status.idle":"2024-11-20T14:32:54.986826Z","shell.execute_reply.started":"2024-11-20T14:32:44.827668Z","shell.execute_reply":"2024-11-20T14:32:54.986185Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.heatmap(conf_mat,annot=True,fmt='.0f');\nplt.title(\"Conf Matrix for Custom CNN Model\");","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T14:32:54.988595Z","iopub.execute_input":"2024-11-20T14:32:54.988869Z","iopub.status.idle":"2024-11-20T14:32:55.433537Z","shell.execute_reply.started":"2024-11-20T14:32:54.988837Z","shell.execute_reply":"2024-11-20T14:32:55.432791Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_predictions(true_classes, predictions, pred_generator, class_indices)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T14:32:55.434944Z","iopub.execute_input":"2024-11-20T14:32:55.435239Z","iopub.status.idle":"2024-11-20T14:32:57.095320Z","shell.execute_reply.started":"2024-11-20T14:32:55.435203Z","shell.execute_reply":"2024-11-20T14:32:57.094595Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluating MobileNetV2 Model","metadata":{}},{"cell_type":"code","source":"class_indices = train_generator.class_indices\nclass_indices = dict((v,k) for k,v in class_indices.items())\npred_generator.reset()\n\npredictions = mobilenet.predict_generator(pred_generator, steps=len(pred_generator.filenames))\npredicted_classes = np.argmax(np.rint(predictions), axis=1)\ntrue_classes = pred_generator.classes\n\nprf, conf_mat = display_results(true_classes, predicted_classes, class_indices.values())\nprf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T14:32:57.096523Z","iopub.execute_input":"2024-11-20T14:32:57.096740Z","iopub.status.idle":"2024-11-20T14:33:58.811806Z","shell.execute_reply.started":"2024-11-20T14:32:57.096716Z","shell.execute_reply":"2024-11-20T14:33:58.811002Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.heatmap(conf_mat,annot=True,fmt='.0f');\nplt.title(\"Conf Matrix for MobileNetV2\");","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T14:33:58.814587Z","iopub.execute_input":"2024-11-20T14:33:58.814798Z","iopub.status.idle":"2024-11-20T14:33:59.268827Z","shell.execute_reply.started":"2024-11-20T14:33:58.814775Z","shell.execute_reply":"2024-11-20T14:33:59.268123Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_predictions(true_classes, predictions, pred_generator, class_indices)\nplt.savefig(\"sample_output.png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T15:16:24.155068Z","iopub.execute_input":"2024-11-20T15:16:24.155360Z","iopub.status.idle":"2024-11-20T15:16:26.279229Z","shell.execute_reply.started":"2024-11-20T15:16:24.155329Z","shell.execute_reply":"2024-11-20T15:16:26.278540Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluating ResNet101V2 Model","metadata":{}},{"cell_type":"code","source":"class_indices = train_generator.class_indices\nclass_indices = dict((v,k) for k,v in class_indices.items())\npred_generator.reset()\n\npredictions = resnet.predict_generator(pred_generator, steps=len(pred_generator.filenames))\npredicted_classes = np.argmax(np.rint(predictions), axis=1)\ntrue_classes = pred_generator.classes\n\nprf, conf_mat = display_results(true_classes, predicted_classes, class_indices.values())\nprf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T15:10:20.816231Z","iopub.execute_input":"2024-11-20T15:10:20.816551Z","iopub.status.idle":"2024-11-20T15:12:46.159228Z","shell.execute_reply.started":"2024-11-20T15:10:20.816518Z","shell.execute_reply":"2024-11-20T15:12:46.158434Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.heatmap(conf_mat,annot=True,fmt='.0f');\nplt.title(\"Conf Matrix for ResNet101V2 Model\");","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T15:12:46.161074Z","iopub.execute_input":"2024-11-20T15:12:46.161371Z","iopub.status.idle":"2024-11-20T15:12:46.681471Z","shell.execute_reply.started":"2024-11-20T15:12:46.161338Z","shell.execute_reply":"2024-11-20T15:12:46.680596Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_predictions(true_classes, predictions, pred_generator, class_indices)\nplt.savefig(\"sample_output.png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T15:15:12.087724Z","iopub.execute_input":"2024-11-20T15:15:12.088007Z","iopub.status.idle":"2024-11-20T15:15:14.327438Z","shell.execute_reply.started":"2024-11-20T15:15:12.087981Z","shell.execute_reply":"2024-11-20T15:15:14.326670Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}